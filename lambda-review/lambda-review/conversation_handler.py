"""
PICASSO Conversation Endpoint Implementation
Secure conversation state management with healthcare compliance
Implements all security hardeners as specified in the implementation plan
"""

import json
import logging
import time
import boto3
import os
import hmac
import hashlib
import uuid
import jwt
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Union
from botocore.exceptions import ClientError, ConnectTimeoutError, ReadTimeoutError

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# Environment Configuration
ENVIRONMENT = os.environ.get('ENVIRONMENT', 'staging')
SUMMARIES_TABLE_NAME = os.environ.get('SUMMARIES_TABLE_NAME', f'{ENVIRONMENT}-conversation-summaries')
MESSAGES_TABLE_NAME = os.environ.get('MESSAGES_TABLE_NAME', f'{ENVIRONMENT}-recent-messages')
JWT_SECRET_KEY_NAME = os.environ.get('JWT_SECRET_KEY_NAME', 'picasso/jwt/signing-key')
AWS_REGION = os.environ.get('AWS_REGION', 'us-east-1')

# Security Limits (hardcoded as per spec)
RATE_LIMIT_REQUESTS = 10
RATE_LIMIT_WINDOW = 10  # seconds
MAX_PAYLOAD_SIZE = 24 * 1024  # 24KB
MAX_MESSAGES_PER_SAVE = 6
STATE_TOKEN_EXPIRY_HOURS = 24

# Memory Management Limits
MAX_RATE_LIMIT_SESSIONS = 1000  # Maximum sessions to track
CLEANUP_INTERVAL_SECONDS = 30  # Time-based cleanup interval
MEMORY_WARNING_THRESHOLD = 800  # Warn when approaching max sessions

# TTL Configuration (healthcare compliance)
SUMMARY_TTL_DAYS = 7
MESSAGES_TTL_HOURS = 24

# Import AWS client manager for timeout protection
try:
    from aws_client_manager import (
        protected_dynamodb_operation,
        protected_secrets_operation,
        timeout_handler,
        CircuitBreakerError,
        aws_client_manager,
        graceful_degradation
    )
    AWS_CLIENT_MANAGER_AVAILABLE = True
    logger.info("‚úÖ AWS client manager loaded with timeout protection")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è AWS client manager not available, using legacy clients: {e}")
    # Fallback to legacy clients without timeout protection
    dynamodb = boto3.client('dynamodb', region_name=AWS_REGION)
    secrets_client = boto3.client('secretsmanager', region_name=AWS_REGION)
    AWS_CLIENT_MANAGER_AVAILABLE = False

# Global state for rate limiting and JWT key caching
rate_limit_store = {}
last_cleanup_time = 0  # Track last cleanup for time-based approach
jwt_signing_key_cache = None
jwt_key_cache_expires = 0

# Import audit logger
try:
    from audit_logger import audit_logger
    AUDIT_LOGGER_AVAILABLE = True
    logger.info("‚úÖ audit_logger module loaded for conversation handler")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è audit_logger not available: {e}")
    AUDIT_LOGGER_AVAILABLE = False

# Import token blacklist system
try:
    from token_blacklist import is_token_blacklisted, TokenBlacklistError
    TOKEN_BLACKLIST_AVAILABLE = True
    logger.info("‚úÖ token_blacklist module loaded for conversation handler")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è token_blacklist not available: {e}")
    TOKEN_BLACKLIST_AVAILABLE = False

class ConversationError(Exception):
    """Base exception for conversation operations"""
    def __init__(self, error_type: str, message: str, status_code: int = 500):
        self.error_type = error_type
        self.message = message
        self.status_code = status_code
        super().__init__(message)

def handle_conversation_action(event, context):
    """
    Main router for conversation actions
    Routes to GET/POST/DELETE operations with full security hardening
    """
    try:
        # Extract operation from query parameters
        query_params = event.get("queryStringParameters") or {}
        operation = query_params.get("operation")
        
        if not operation:
            return _error_response("MISSING_OPERATION", "Operation parameter required", 400)
        
        # Route to appropriate handler
        if operation == "get":
            return handle_get_conversation(event)
        elif operation == "save":
            return handle_save_conversation(event)
        elif operation == "clear":
            return handle_clear_conversation(event)
        else:
            return _error_response("INVALID_OPERATION", f"Unknown operation: {operation}", 400)
            
    except ConversationError as e:
        return _error_response(e.error_type, e.message, e.status_code)
    except Exception as e:
        logger.exception("‚ùå Critical error in conversation handler")
        return _error_response("SYSTEM_ERROR", "Internal server error", 500)

def handle_get_conversation(event):
    """
    GET Operation: Retrieve conversation state
    Security: State token validation, turn rotation
    """
    try:
        # 1. Validate and parse state token
        token_data = _validate_state_token(event)
        session_id = token_data['sessionId']
        tenant_id = token_data['tenantId']
        current_turn = token_data['turn']
        
        # 2. Rate limiting check
        _check_rate_limit(session_id)
        
        logger.info(f"[{tenant_id[:8]}...] üìñ Getting conversation state for session {session_id[:12]}...")
        
        # 3. Retrieve conversation state from DynamoDB with timeout protection
        conversation_state = _get_conversation_from_db(session_id, tenant_id)
        
        # 4. Generate new rotated token
        new_token = _generate_rotated_token(token_data)
        
        # 5. Audit successful retrieval (fail-closed for security)
        if AUDIT_LOGGER_AVAILABLE:
            try:
                audit_logger._log_audit_event(
                    tenant_id=tenant_id,
                    event_type='CONVERSATION_RETRIEVED',
                    session_id=session_id,
                    context={'turn': current_turn + 1, 'has_state': bool(conversation_state)}
                )
            except Exception as e:
                logger.error(f"‚ùå Audit logging failed for retrieval: {e}")
                raise ConversationError("AUDIT_FAILED", "Security audit service unavailable", 503)
        else:
            logger.error("‚ùå Audit logger unavailable for retrieval operation")
            raise ConversationError("AUDIT_UNAVAILABLE", "Security audit service required", 503)
        
        # 6. Return response with rotated token
        response_data = {
            "sessionId": session_id,
            "state": conversation_state,
            "stateToken": new_token
        }
        
        return _success_response(response_data)
        
    except ConversationError:
        raise
    except Exception as e:
        logger.exception("‚ùå Error retrieving conversation")
        raise ConversationError("RETRIEVAL_FAILED", str(e), 500)

def handle_save_conversation(event):
    """
    POST Operation: Save conversation state with delta updates
    Security: Compare-and-swap, DLP scrubbing, payload validation
    """
    try:
        # 1. Validate and parse state token
        token_data = _validate_state_token(event)
        session_id = token_data['sessionId']
        tenant_id = token_data['tenantId']
        current_turn = token_data['turn']
        
        # 2. Rate limiting check
        _check_rate_limit(session_id)
        
        # 3. Parse and validate request body
        body = _parse_request_body(event)
        request_turn = body.get('turn')
        delta = body.get('delta', {})
        
        if request_turn is None or request_turn != current_turn:
            # Version conflict - return server's current state
            current_state = _get_conversation_from_db(session_id, tenant_id)
            
            # CRITICAL FIX: Handle case where DB has no state yet (new conversation)
            # _get_conversation_from_db now always returns a state with turn field
            if current_state and 'turn' in current_state:
                actual_turn = current_state['turn']
            else:
                # Fallback: No state in DB yet, this is likely the first message
                actual_turn = 0
            
            # SPECIAL CASE: If this is the first message (request_turn=0, token_turn=0, actual_turn=0)
            # but there's a version mismatch, allow it to proceed as it's likely a valid first message
            if request_turn == 0 and current_turn == 0 and actual_turn == 0:
                logger.info(f"First message scenario: allowing turn 0 to proceed for session {session_id[:12]}...")
                # Continue processing the message instead of returning conflict
            else:
                # Update token data with the actual turn from database
                updated_token_data = {**token_data, 'turn': actual_turn}
                server_token = _generate_rotated_token(updated_token_data, increment_turn=False)
                
                logger.warning(f"Version conflict: request_turn={request_turn}, token_turn={current_turn}, actual_turn={actual_turn}")
                
                return _error_response(
                    "VERSION_CONFLICT",
                    "Conversation state changed by another session",
                    409,
                    extra_data={
                        "stateToken": server_token,
                        "currentTurn": actual_turn  # Return actual turn from database
                    }
                )
        
        # 4. Validate payload limits
        _validate_save_payload(body)
        
        logger.info(f"[{tenant_id[:8]}...] üíæ Saving conversation delta for session {session_id[:12]}...")
        
        # 5. Apply DLP scrubbing to delta
        scrubbed_delta = _scrub_conversation_data(delta)
        
        # 6. Compare-and-swap update to DynamoDB
        updated_state = _save_conversation_to_db(session_id, tenant_id, scrubbed_delta, current_turn)
        
        # 7. Generate new rotated token
        new_token = _generate_rotated_token(token_data)
        
        # 8. Audit successful save (fail-closed for security)
        if AUDIT_LOGGER_AVAILABLE:
            try:
                audit_logger._log_audit_event(
                    tenant_id=tenant_id,
                    event_type='CONVERSATION_SAVED',
                    session_id=session_id,
                    context={
                        'turn': current_turn + 1,
                        'delta_keys': list(scrubbed_delta.keys()),
                        'message_count': len(scrubbed_delta.get('lastMessages', []))
                    }
                )
            except Exception as e:
                logger.error(f"‚ùå Audit logging failed for save: {e}")
                raise ConversationError("AUDIT_FAILED", "Security audit service unavailable", 503)
        else:
            logger.error("‚ùå Audit logger unavailable for save operation")
            raise ConversationError("AUDIT_UNAVAILABLE", "Security audit service required", 503)
        
        # 9. Return success with rotated token
        response_data = {
            "stateToken": new_token,
            "turn": current_turn + 1
        }
        
        return _success_response(response_data)
        
    except ConversationError:
        raise
    except Exception as e:
        logger.exception("‚ùå Error saving conversation")
        raise ConversationError("SAVE_FAILED", str(e), 500)

def handle_clear_conversation(event):
    """
    DELETE Operation: Clear conversation with verified deletion
    Security: Read-after-write verification, comprehensive audit
    """
    try:
        # 1. Validate and parse state token
        token_data = _validate_state_token(event)
        session_id = token_data['sessionId']
        tenant_id = token_data['tenantId']
        
        # 2. Rate limiting check
        _check_rate_limit(session_id)
        
        logger.info(f"[{tenant_id[:8]}...] üßπ Clearing conversation for session {session_id[:12]}...")
        
        # 3. Delete from both tables
        deletion_report = _delete_conversation_from_db(session_id, tenant_id)
        
        # 4. Verify deletion with read-after-write
        verification_result = _verify_conversation_deleted(session_id)
        
        # 5. Audit successful clear (fail-closed for security)
        if AUDIT_LOGGER_AVAILABLE:
            try:
                audit_logger._log_audit_event(
                    tenant_id=tenant_id,
                    event_type='CONVERSATION_CLEARED',
                    session_id=session_id,
                    context={
                        'messages_deleted': deletion_report['messages_deleted'],
                        'summaries_deleted': deletion_report['summaries_deleted'],
                        'verified': verification_result
                    }
                )
            except Exception as e:
                logger.error(f"‚ùå Audit logging failed for clear: {e}")
                raise ConversationError("AUDIT_FAILED", "Security audit service unavailable", 503)
        else:
            logger.error("‚ùå Audit logger unavailable for clear operation")
            raise ConversationError("AUDIT_UNAVAILABLE", "Security audit service required", 503)
        
        # 6. Return deletion report
        response_data = {
            "sessionId": session_id,
            "report": {
                "messages_deleted": deletion_report['messages_deleted'],
                "summaries_deleted": deletion_report['summaries_deleted'],
                "verified": verification_result
            },
            "stateToken": None  # No token after clear
        }
        
        return _success_response(response_data)
        
    except ConversationError:
        raise
    except Exception as e:
        logger.exception("‚ùå Error clearing conversation")
        raise ConversationError("CLEAR_FAILED", str(e), 500)

def _validate_state_token(event):
    """
    Validate HMAC/JWT state token and extract claims
    Security hardener: Token validation with expiry check and blacklist verification
    """
    try:
        # Extract Bearer token from Authorization header
        headers = event.get("headers", {}) or {}
        auth_header = headers.get("Authorization") or headers.get("authorization")
        
        if not auth_header or not auth_header.startswith("Bearer "):
            raise ConversationError("TOKEN_INVALID", "Missing or invalid Authorization header", 401)
        
        token = auth_header[7:]  # Remove "Bearer " prefix
        
        # SECURITY: Check token blacklist BEFORE JWT validation (fail-fast security)
        if TOKEN_BLACKLIST_AVAILABLE:
            try:
                if is_token_blacklisted(token):
                    logger.warning(f"üö´ Blacklisted token rejected in conversation handler")
                    
                    # Audit blacklisted token usage attempt (fail-closed for security)
                    if AUDIT_LOGGER_AVAILABLE:
                        try:
                            audit_logger._log_audit_event(
                                tenant_id="unknown",
                                event_type='BLACKLISTED_TOKEN_USAGE_ATTEMPT',
                                session_id="unknown",
                                context={'source': 'conversation_handler', 'action': 'token_validation'}
                            )
                        except Exception as e:
                            logger.error(f"‚ùå Failed to audit blacklisted token attempt: {e}")
                            # Continue with token rejection even if audit fails
                    
                    raise ConversationError("TOKEN_REVOKED", "Authentication token has been revoked", 401)
                    
            except TokenBlacklistError as e:
                # Blacklist service error - fail closed for security
                logger.error(f"‚ùå Blacklist check failed: {e.message}")
                if e.error_type == "BLACKLIST_UNAVAILABLE":
                    # Service unavailable - allow operation but log security warning
                    logger.warning("‚ö†Ô∏è Blacklist service unavailable - proceeding with JWT validation only")
                else:
                    # Other errors - fail closed
                    raise ConversationError("TOKEN_VALIDATION_FAILED", "Token security verification failed", 500)
        else:
            logger.warning("‚ö†Ô∏è Token blacklist system not available - proceeding with JWT validation only")
        
        # Get JWT signing key
        signing_key = _get_jwt_signing_key()
        
        # Decode and validate JWT
        try:
            payload = jwt.decode(token, signing_key, algorithms=['HS256'])
        except jwt.ExpiredSignatureError:
            raise ConversationError("TOKEN_EXPIRED", "State token has expired", 401)
        except jwt.InvalidTokenError as e:
            raise ConversationError("TOKEN_INVALID", f"Invalid token: {str(e)}", 401)
        
        # Validate required fields
        required_fields = ['sessionId', 'tenantId', 'turn', 'iat', 'exp']
        for field in required_fields:
            if field not in payload:
                raise ConversationError("TOKEN_INVALID", f"Missing required field: {field}", 401)
        
        logger.info(f"[{payload['tenantId'][:8]}...] ‚úÖ Valid state token for turn {payload['turn']} (blacklist checked)")
        return payload
        
    except ConversationError:
        raise
    except Exception as e:
        logger.error(f"‚ùå Token validation error: {str(e)}")
        raise ConversationError("TOKEN_INVALID", "Token validation failed", 401)

def _check_rate_limit(session_id):
    """
    Rate limiting: 10 requests per 10 seconds per session
    Security hardener: Prevent abuse with memory leak protection and bounds
    """
    current_time = time.time()
    window_start = current_time - RATE_LIMIT_WINDOW
    
    # Time-based cleanup to prevent memory leak
    _cleanup_rate_limit_store(current_time)
    
    # Memory protection: enforce maximum sessions limit
    if len(rate_limit_store) >= MAX_RATE_LIMIT_SESSIONS and session_id not in rate_limit_store:
        # LRU eviction: remove oldest session
        _evict_oldest_session(current_time)
        logger.warning(f"üö® Rate limit store at capacity ({MAX_RATE_LIMIT_SESSIONS}), evicted oldest session")
    
    # Clean old entries for this session
    if session_id in rate_limit_store:
        rate_limit_store[session_id] = [
            timestamp for timestamp in rate_limit_store[session_id]
            if timestamp > window_start
        ]
    else:
        rate_limit_store[session_id] = []
    
    # Check if limit exceeded
    if len(rate_limit_store[session_id]) >= RATE_LIMIT_REQUESTS:
        raise ConversationError("RATE_LIMITED", "Too many requests", 429)
    
    # Add current request
    rate_limit_store[session_id].append(current_time)
    
    # Memory usage monitoring
    _monitor_memory_usage()

def _cleanup_rate_limit_store(current_time):
    """
    Time-based cleanup of expired rate limit entries to prevent memory leak
    Security fix: Prevent unbounded memory growth with predictable cleanup
    """
    global rate_limit_store, last_cleanup_time
    
    # Time-based cleanup instead of request-count based to handle low-traffic scenarios
    if current_time - last_cleanup_time < CLEANUP_INTERVAL_SECONDS:
        return
    
    last_cleanup_time = current_time
    window_start = current_time - RATE_LIMIT_WINDOW
    sessions_to_remove = []
    
    for session_id, timestamps in rate_limit_store.items():
        # Remove expired timestamps
        active_timestamps = [ts for ts in timestamps if ts > window_start]
        if active_timestamps:
            rate_limit_store[session_id] = active_timestamps
        else:
            sessions_to_remove.append(session_id)
    
    # Remove empty sessions
    for session_id in sessions_to_remove:
        del rate_limit_store[session_id]
    
    logger.info(f"üßπ Time-based rate limit cleanup: removed {len(sessions_to_remove)} expired sessions, {len(rate_limit_store)} active sessions remain")

def _evict_oldest_session(current_time):
    """
    LRU eviction: remove the session with the oldest timestamp
    Memory protection: prevent unbounded growth under high load
    """
    global rate_limit_store
    
    if not rate_limit_store:
        return
    
    # Find session with oldest timestamp
    oldest_session = None
    oldest_timestamp = current_time
    
    for session_id, timestamps in rate_limit_store.items():
        if timestamps and min(timestamps) < oldest_timestamp:
            oldest_timestamp = min(timestamps)
            oldest_session = session_id
    
    # Remove oldest session
    if oldest_session:
        del rate_limit_store[oldest_session]
        logger.info(f"üóëÔ∏è LRU evicted session {oldest_session[:12]}... (oldest timestamp: {oldest_timestamp})")

def _monitor_memory_usage():
    """
    Monitor rate limit store memory usage and log warnings
    Memory protection: proactive monitoring for DoS prevention
    """
    session_count = len(rate_limit_store)
    
    if session_count >= MEMORY_WARNING_THRESHOLD:
        total_timestamps = sum(len(timestamps) for timestamps in rate_limit_store.values())
        logger.warning(f"‚ö†Ô∏è Rate limit memory usage high: {session_count}/{MAX_RATE_LIMIT_SESSIONS} sessions, {total_timestamps} total timestamps")
    
    # Log memory stats every 100 sessions for monitoring
    if session_count > 0 and session_count % 100 == 0:
        total_timestamps = sum(len(timestamps) for timestamps in rate_limit_store.values())
        avg_timestamps = total_timestamps / session_count if session_count > 0 else 0
        logger.info(f"üìä Rate limit memory stats: {session_count} sessions, {total_timestamps} timestamps, {avg_timestamps:.1f} avg/session")

def _parse_request_body(event):
    """
    Parse and validate request body
    Security hardener: Payload size validation
    """
    body_str = event.get("body", "")
    if not body_str:
        raise ConversationError("MISSING_BODY", "Request body required", 400)
    
    # Check payload size
    body_size = len(body_str.encode('utf-8'))
    if body_size > MAX_PAYLOAD_SIZE:
        raise ConversationError("PAYLOAD_TOO_LARGE", f"Payload size {body_size} exceeds {MAX_PAYLOAD_SIZE} bytes", 413)
    
    try:
        return json.loads(body_str)
    except json.JSONDecodeError as e:
        raise ConversationError("INVALID_JSON", f"Invalid JSON in request body: {str(e)}", 400)

def _validate_save_payload(body):
    """
    Validate save operation payload
    Security hardener: Message count and structure validation
    """
    delta = body.get('delta', {})
    
    # Validate message count in lastMessages
    last_messages = delta.get('lastMessages', [])
    if len(last_messages) > MAX_MESSAGES_PER_SAVE:
        raise ConversationError("PAYLOAD_TOO_LARGE", f"Too many messages: {len(last_messages)} > {MAX_MESSAGES_PER_SAVE}", 413)
    
    # Validate message structure
    for msg in last_messages:
        if not isinstance(msg, dict) or 'role' not in msg or 'text' not in msg:
            raise ConversationError("INVALID_MESSAGE", "Messages must have 'role' and 'text' fields", 400)

def _scrub_conversation_data(data):
    """
    DLP scrubbing pipeline using audit_logger patterns
    Security hardener: PII protection with fail-safe
    Security fix: Fail-closed approach - reject operation if scrubbing fails
    """
    if not AUDIT_LOGGER_AVAILABLE:
        logger.error("‚ùå DLP scrubbing unavailable - audit_logger not loaded")
        raise ConversationError("DLP_UNAVAILABLE", "Data protection service unavailable", 503)
    
    try:
        # Use audit_logger's PII scanning
        scrubbed_data = audit_logger._scan_for_pii(data)
        logger.info("üõ°Ô∏è Applied DLP scrubbing to conversation data")
        
        # Validate that scrubbing actually occurred by checking for redacted patterns
        data_str = json.dumps(data, separators=(',', ':'))
        scrubbed_str = json.dumps(scrubbed_data, separators=(',', ':'))
        
        # If data contains potential PII patterns, ensure scrubbing happened
        if len(data_str) > 50 and data_str == scrubbed_str:
            # Comprehensive check using audit_logger's PII patterns for consistency
            from audit_logger import PII_PATTERNS
            
            # Check for any PII patterns that should have been scrubbed
            pii_detected = False
            for pattern_name, pattern in PII_PATTERNS.items():
                if pattern.search(scrubbed_str):
                    logger.error(f"‚ùå DLP scrubbing verification failed - {pattern_name} pattern detected in output")
                    pii_detected = True
                    break
            
            if pii_detected:
                raise ConversationError("DLP_FAILED", "Data protection validation failed", 500)
        
        return scrubbed_data
    except ConversationError:
        raise
    except Exception as e:
        logger.error(f"‚ùå DLP scrubbing failed: {str(e)}")
        # Fail-closed: reject the operation rather than storing unscrubbed data
        raise ConversationError("DLP_FAILED", "Data protection service error", 500)

def _get_conversation_from_db(session_id, tenant_id):
    """
    Retrieve conversation state from DynamoDB tables with timeout protection
    """
    try:
        # Get summary from conversation-summaries table with timeout protection
        if AWS_CLIENT_MANAGER_AVAILABLE:
            try:
                summary_response = protected_dynamodb_operation(
                    'get_item',
                    TableName=SUMMARIES_TABLE_NAME,
                    Key={'sessionId': {'S': session_id}}
                )
            except (ConnectTimeoutError, ReadTimeoutError, CircuitBreakerError) as e:
                logger.error(f"‚è∞ DynamoDB timeout getting summary for session {session_id[:12]}...: {e}")
                raise ConversationError("DB_TIMEOUT", "Database service temporarily unavailable", 503)
        else:
            # Fallback to legacy client
            summary_response = dynamodb.get_item(
                TableName=SUMMARIES_TABLE_NAME,
                Key={'sessionId': {'S': session_id}}
            )
        
        # Get recent messages from recent-messages table with timeout protection
        if AWS_CLIENT_MANAGER_AVAILABLE:
            try:
                messages_response = protected_dynamodb_operation(
                    'query',
                    TableName=MESSAGES_TABLE_NAME,
                    KeyConditionExpression='sessionId = :sid',
                    ExpressionAttributeValues={':sid': {'S': session_id}},
                    ScanIndexForward=True,  # Oldest first
                    Limit=50  # Reasonable limit
                )
            except (ConnectTimeoutError, ReadTimeoutError, CircuitBreakerError) as e:
                logger.error(f"‚è∞ DynamoDB timeout getting messages for session {session_id[:12]}...: {e}")
                raise ConversationError("DB_TIMEOUT", "Database service temporarily unavailable", 503)
        else:
            # Fallback to legacy client
            messages_response = dynamodb.query(
                TableName=MESSAGES_TABLE_NAME,
                KeyConditionExpression='sessionId = :sid',
                ExpressionAttributeValues={':sid': {'S': session_id}},
                ScanIndexForward=True,  # Oldest first
                Limit=50  # Reasonable limit
            )
        
        # Build state object
        state = {}
        
        if 'Item' in summary_response:
            item = summary_response['Item']
            state = {
                'summary': item.get('summary', {}).get('S', ''),
                'facts_ledger': json.loads(item.get('facts_ledger', {}).get('S', '{}')),
                'pending_action': item.get('pending_action', {}).get('S'),
                'turn': int(item.get('turn', {}).get('N', '0'))
            }
        
        if 'Items' in messages_response and messages_response['Items']:
            messages = []
            for item in messages_response['Items']:
                messages.append({
                    'role': item.get('role', {}).get('S', ''),
                    'text': item.get('content', {}).get('S', '')
                })
            state['lastMessages'] = messages
        
        # CRITICAL FIX: Always return a state object with at least a turn field
        # This prevents 409 conflicts when no conversation state exists yet
        if not state:
            state = {'turn': 0}
        return state
        
    except ClientError as e:
        logger.error(f"‚ùå DynamoDB error retrieving conversation: {e}")
        raise ConversationError("DB_ERROR", "Database error during retrieval", 500)

def _save_conversation_to_db(session_id, tenant_id, delta, expected_turn):
    """
    Save conversation state to DynamoDB with compare-and-swap
    Security hardener: Concurrency control
    """
    try:
        current_time = datetime.utcnow()
        summary_ttl = int((current_time + timedelta(days=SUMMARY_TTL_DAYS)).timestamp())
        message_ttl = int((current_time + timedelta(hours=MESSAGES_TTL_HOURS)).timestamp())
        
        # Update summary if provided
        if any(key in delta for key in ['summary_update', 'facts_update', 'pending_action']):
            summary_item = {
                'sessionId': {'S': session_id},
                'tenantId': {'S': tenant_id},
                'turn': {'N': str(expected_turn + 1)},
                'updatedAt': {'S': current_time.isoformat() + 'Z'},
                'expires_at': {'N': str(summary_ttl)}
            }
            
            if 'summary_update' in delta:
                summary_item['summary'] = {'S': delta['summary_update']}
            if 'facts_update' in delta:
                summary_item['facts_ledger'] = {'S': json.dumps(delta['facts_update'])}
            if 'pending_action' in delta:
                summary_item['pending_action'] = {'S': delta['pending_action']}
            
            # Compare-and-swap: only update if turn matches with timeout protection
            try:
                if AWS_CLIENT_MANAGER_AVAILABLE:
                    try:
                        protected_dynamodb_operation(
                            'put_item',
                            TableName=SUMMARIES_TABLE_NAME,
                            Item=summary_item,
                            ConditionExpression='attribute_not_exists(sessionId) OR turn = :expected_turn',
                            ExpressionAttributeValues={':expected_turn': {'N': str(expected_turn)}}
                        )
                    except (ConnectTimeoutError, ReadTimeoutError, CircuitBreakerError) as e:
                        logger.error(f"‚è∞ DynamoDB timeout saving summary for session {session_id[:12]}...: {e}")
                        raise ConversationError("DB_TIMEOUT", "Database service temporarily unavailable", 503)
                else:
                    # Fallback to legacy client
                    dynamodb.put_item(
                        TableName=SUMMARIES_TABLE_NAME,
                        Item=summary_item,
                        ConditionExpression='attribute_not_exists(sessionId) OR turn = :expected_turn',
                        ExpressionAttributeValues={':expected_turn': {'N': str(expected_turn)}}
                    )
            except ClientError as e:
                if e.response['Error']['Code'] == 'ConditionalCheckFailedException':
                    raise ConversationError("VERSION_CONFLICT", "Concurrent update detected", 409)
                raise
        
        # Save new messages if provided
        if 'appendUser' in delta or 'appendAssistant' in delta:
            timestamp_base = int(current_time.timestamp() * 1000)  # milliseconds
            
            for i, (role, message_data) in enumerate([
                ('user', delta.get('appendUser')),
                ('assistant', delta.get('appendAssistant'))
            ]):
                if message_data:
                    message_item = {
                        'sessionId': {'S': session_id},
                        'timestamp': {'N': str(timestamp_base + i)},
                        'messageId': {'S': str(uuid.uuid4())},
                        'role': {'S': role},
                        'content': {'S': message_data.get('text', '')},
                        'expires_at': {'N': str(message_ttl)}
                    }
                    
                    if AWS_CLIENT_MANAGER_AVAILABLE:
                        try:
                            protected_dynamodb_operation(
                                'put_item',
                                TableName=MESSAGES_TABLE_NAME,
                                Item=message_item
                            )
                        except (ConnectTimeoutError, ReadTimeoutError, CircuitBreakerError) as e:
                            logger.error(f"‚è∞ DynamoDB timeout saving message for session {session_id[:12]}...: {e}")
                            raise ConversationError("DB_TIMEOUT", "Database service temporarily unavailable", 503)
                    else:
                        # Fallback to legacy client
                        dynamodb.put_item(
                            TableName=MESSAGES_TABLE_NAME,
                            Item=message_item
                        )
        
        logger.info(f"[{tenant_id[:8]}...] ‚úÖ Conversation saved successfully")
        
    except ConversationError:
        raise
    except ClientError as e:
        logger.error(f"‚ùå DynamoDB error saving conversation: {e}")
        raise ConversationError("DB_ERROR", "Database error during save", 500)

def _delete_conversation_from_db(session_id, tenant_id):
    """
    Delete conversation from both tables with counting
    """
    try:
        messages_deleted = 0
        summaries_deleted = 0
        
        # Delete from messages table with timeout protection
        if AWS_CLIENT_MANAGER_AVAILABLE:
            try:
                messages_response = protected_dynamodb_operation(
                    'query',
                    TableName=MESSAGES_TABLE_NAME,
                    KeyConditionExpression='sessionId = :sid',
                    ExpressionAttributeValues={':sid': {'S': session_id}},
                    ProjectionExpression='sessionId, #ts',
                    ExpressionAttributeNames={'#ts': 'timestamp'}
                )
            except (ConnectTimeoutError, ReadTimeoutError, CircuitBreakerError) as e:
                logger.error(f"‚è∞ DynamoDB timeout querying messages for deletion: {e}")
                raise ConversationError("DB_TIMEOUT", "Database service temporarily unavailable", 503)
        else:
            # Fallback to legacy client
            messages_response = dynamodb.query(
                TableName=MESSAGES_TABLE_NAME,
                KeyConditionExpression='sessionId = :sid',
                ExpressionAttributeValues={':sid': {'S': session_id}},
                ProjectionExpression='sessionId, #ts',
                ExpressionAttributeNames={'#ts': 'timestamp'}
            )
        
        for item in messages_response.get('Items', []):
            if AWS_CLIENT_MANAGER_AVAILABLE:
                try:
                    protected_dynamodb_operation(
                        'delete_item',
                        TableName=MESSAGES_TABLE_NAME,
                        Key={
                            'sessionId': {'S': session_id},
                            'timestamp': item['timestamp']
                        }
                    )
                except (ConnectTimeoutError, ReadTimeoutError, CircuitBreakerError) as e:
                    logger.error(f"‚è∞ DynamoDB timeout deleting message: {e}")
                    raise ConversationError("DB_TIMEOUT", "Database service temporarily unavailable", 503)
            else:
                # Fallback to legacy client
                dynamodb.delete_item(
                    TableName=MESSAGES_TABLE_NAME,
                    Key={
                        'sessionId': {'S': session_id},
                        'timestamp': item['timestamp']
                    }
                )
            messages_deleted += 1
        
        # Delete from summaries table with timeout protection
        try:
            if AWS_CLIENT_MANAGER_AVAILABLE:
                try:
                    protected_dynamodb_operation(
                        'delete_item',
                        TableName=SUMMARIES_TABLE_NAME,
                        Key={'sessionId': {'S': session_id}}
                    )
                except (ConnectTimeoutError, ReadTimeoutError, CircuitBreakerError) as e:
                    logger.error(f"‚è∞ DynamoDB timeout deleting summary: {e}")
                    raise ConversationError("DB_TIMEOUT", "Database service temporarily unavailable", 503)
            else:
                # Fallback to legacy client
                dynamodb.delete_item(
                    TableName=SUMMARIES_TABLE_NAME,
                    Key={'sessionId': {'S': session_id}}
                )
            summaries_deleted = 1
        except ClientError as e:
            if e.response['Error']['Code'] != 'ResourceNotFoundException':
                raise
        
        return {
            'messages_deleted': messages_deleted,
            'summaries_deleted': summaries_deleted
        }
        
    except ClientError as e:
        logger.error(f"‚ùå DynamoDB error deleting conversation: {e}")
        raise ConversationError("DB_ERROR", "Database error during deletion", 500)

def _verify_conversation_deleted(session_id):
    """
    Verify deletion with read-after-write
    Security hardener: Verified clear operation
    """
    try:
        # Check summaries table with timeout protection
        if AWS_CLIENT_MANAGER_AVAILABLE:
            try:
                summary_response = protected_dynamodb_operation(
                    'get_item',
                    TableName=SUMMARIES_TABLE_NAME,
                    Key={'sessionId': {'S': session_id}}
                )
                
                # Check messages table
                messages_response = protected_dynamodb_operation(
                    'query',
                    TableName=MESSAGES_TABLE_NAME,
                    KeyConditionExpression='sessionId = :sid',
                    ExpressionAttributeValues={':sid': {'S': session_id}},
                    Limit=1
                )
            except (ConnectTimeoutError, ReadTimeoutError, CircuitBreakerError) as e:
                logger.error(f"‚è∞ DynamoDB timeout during verification: {e}")
                # Return False for verification failure due to timeout
                return False
        else:
            # Fallback to legacy client
            summary_response = dynamodb.get_item(
                TableName=SUMMARIES_TABLE_NAME,
                Key={'sessionId': {'S': session_id}}
            )
            
            # Check messages table
            messages_response = dynamodb.query(
                TableName=MESSAGES_TABLE_NAME,
                KeyConditionExpression='sessionId = :sid',
                ExpressionAttributeValues={':sid': {'S': session_id}},
                Limit=1
            )
        
        # Verification passes if both tables are empty
        summary_empty = 'Item' not in summary_response
        messages_empty = not messages_response.get('Items', [])
        
        verified = summary_empty and messages_empty
        logger.info(f"üîç Deletion verification: {'‚úÖ PASSED' if verified else '‚ùå FAILED'}")
        
        return verified
        
    except ClientError as e:
        logger.error(f"‚ùå DynamoDB error during verification: {e}")
        return False

def _generate_rotated_token(token_data, increment_turn=True):
    """
    Generate new state token with incremented turn
    Security hardener: Token rotation
    """
    try:
        signing_key = _get_jwt_signing_key()
        
        new_payload = {
            'sessionId': token_data['sessionId'],
            'tenantId': token_data['tenantId'],
            'turn': token_data['turn'] + (1 if increment_turn else 0),
            'iat': int(time.time()),
            'exp': int(time.time()) + (STATE_TOKEN_EXPIRY_HOURS * 3600)
        }
        
        return jwt.encode(new_payload, signing_key, algorithm='HS256')
        
    except Exception as e:
        logger.error(f"‚ùå Token generation error: {str(e)}")
        raise ConversationError("TOKEN_GENERATION_FAILED", "Failed to generate new token", 500)

def _get_jwt_signing_key():
    """
    Get JWT signing key from AWS Secrets Manager with secure caching
    Security fix: Reduced cache time to 60 seconds for better key rotation support
    """
    global jwt_signing_key_cache, jwt_key_cache_expires
    
    current_time = time.time()
    if jwt_signing_key_cache and current_time < jwt_key_cache_expires:
        return jwt_signing_key_cache
    
    try:
        if AWS_CLIENT_MANAGER_AVAILABLE:
            try:
                def get_secret_operation():
                    return protected_secrets_operation(
                        'get_secret_value',
                        SecretId=JWT_SECRET_KEY_NAME
                    )
                
                response = graceful_degradation.handle_secrets_with_cache(
                    JWT_SECRET_KEY_NAME, get_secret_operation
                )
                key = response['SecretString']
                
            except (ConnectTimeoutError, ReadTimeoutError, CircuitBreakerError) as e:
                logger.error(f"‚è∞ Secrets Manager timeout getting JWT key (no cache available): {e}")
                # Clear cache on timeout to force retry
                jwt_signing_key_cache = None
                jwt_key_cache_expires = 0
                raise ConversationError("JWT_KEY_TIMEOUT", "Authentication service temporarily unavailable", 503)
        else:
            # Fallback to legacy client
            response = secrets_client.get_secret_value(SecretId=JWT_SECRET_KEY_NAME)
            key = response['SecretString']
        
        # Validate key format before caching
        if not key or len(key) < 32:
            logger.error("‚ùå Invalid JWT signing key format")
            raise ConversationError("JWT_KEY_ERROR", "Invalid signing key", 500)
        
        jwt_signing_key_cache = key
        jwt_key_cache_expires = current_time + 60  # Reduced to 60 seconds for security
        return jwt_signing_key_cache
    except ClientError as e:
        logger.error(f"‚ùå Failed to get JWT signing key: {e}")
        # Clear cache on failure
        jwt_signing_key_cache = None
        jwt_key_cache_expires = 0
        raise ConversationError("JWT_KEY_ERROR", "Authentication service unavailable", 500)

def _success_response(data, request_headers=None, tenant_hash=None):
    """
    Create successful response with secure tenant-specific CORS headers
    Security: Implements tenant-specific CORS validation
    """
    headers = {
        "Content-Type": "application/json",
        "Access-Control-Allow-Headers": "Content-Type,Authorization",
        "Access-Control-Allow-Methods": "GET,POST,DELETE,OPTIONS"
    }
    
    # Apply secure CORS validation (import from lambda_function)
    try:
        # Import the secure CORS validation function
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        from lambda_function import validate_cors_origin
        
        allowed_origin, is_valid = validate_cors_origin(request_headers, tenant_hash, None)
        
        if allowed_origin:
            headers["Access-Control-Allow-Origin"] = allowed_origin
            headers["Access-Control-Allow-Credentials"] = "true"
            logger.info(f"[{tenant_hash[:8] if tenant_hash else 'unknown'}...] SECURE CORS: Success response with origin {allowed_origin}")
        elif not is_valid:
            # CORS violation - browser will reject
            logger.warning(f"[{tenant_hash[:8] if tenant_hash else 'unknown'}...] CORS VIOLATION: Origin rejected in success response")
        else:
            # Direct API access
            logger.info(f"[{tenant_hash[:8] if tenant_hash else 'unknown'}...] Direct API access - no CORS headers in success response")
    except Exception as e:
        logger.error(f"Error validating CORS in success response: {e}")
        # Fail closed - don't set CORS headers on error
    
    return {
        "statusCode": 200,
        "headers": headers,
        "body": json.dumps(data, separators=(',', ':'))
    }

def _error_response(error_type, message, status_code, extra_data=None, request_headers=None, tenant_hash=None):
    """
    Create typed error response for client handling with secure CORS
    Security hardener: Standardized error contract with information disclosure protection
    Security fix: Sanitize error messages to prevent internal information disclosure
    Security enhancement: Tenant-specific CORS validation
    """
    # Sanitize error messages in production to avoid revealing internal details
    production_env = ENVIRONMENT.lower() == 'production'
    
    # Safe error messages for production
    safe_messages = {
        "TOKEN_INVALID": "Invalid authentication token",
        "TOKEN_EXPIRED": "Authentication token expired",
        "VERSION_CONFLICT": "Conversation state changed by another session",
        "RATE_LIMITED": "Too many requests",
        "PAYLOAD_TOO_LARGE": "Request payload too large",
        "DLP_FAILED": "Data protection validation failed",
        "DLP_UNAVAILABLE": "Data protection service unavailable",
        "DB_ERROR": "Database service temporarily unavailable",
        "DB_TIMEOUT": "Database service temporarily unavailable",
        "JWT_KEY_TIMEOUT": "Authentication service temporarily unavailable",
        "SYSTEM_ERROR": "Internal service error",
        "AUDIT_FAILED": "Security audit service unavailable",
        "AUDIT_UNAVAILABLE": "Security audit service required"
    }
    
    # Use safe message in production or original message in development
    safe_message = safe_messages.get(error_type, "Service error") if production_env else message
    
    error_data = {
        "error": error_type,
        "message": safe_message
    }
    
    # Only include extra data in non-production environments or for safe fields
    if extra_data:
        safe_extra_fields = {'stateToken', 'currentTurn', 'sessionId'}
        if production_env:
            # Only include safe fields in production
            safe_extra = {k: v for k, v in extra_data.items() if k in safe_extra_fields}
            error_data.update(safe_extra)
        else:
            error_data.update(extra_data)
    
    # Apply secure CORS validation
    headers = {
        "Content-Type": "application/json",
        "Access-Control-Allow-Headers": "Content-Type,Authorization",
        "Access-Control-Allow-Methods": "GET,POST,DELETE,OPTIONS"
    }
    
    try:
        # Import the secure CORS validation function
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        from lambda_function import validate_cors_origin
        
        allowed_origin, is_valid = validate_cors_origin(request_headers, tenant_hash, None)
        
        if allowed_origin:
            headers["Access-Control-Allow-Origin"] = allowed_origin
            headers["Access-Control-Allow-Credentials"] = "true"
            logger.info(f"[{tenant_hash[:8] if tenant_hash else 'unknown'}...] SECURE CORS: Error response with origin {allowed_origin}")
        elif not is_valid:
            # CORS violation - browser will reject
            logger.warning(f"[{tenant_hash[:8] if tenant_hash else 'unknown'}...] CORS VIOLATION: Origin rejected in error response")
        else:
            # Direct API access
            logger.info(f"[{tenant_hash[:8] if tenant_hash else 'unknown'}...] Direct API access - no CORS headers in error response")
    except Exception as e:
        logger.error(f"Error validating CORS in error response: {e}")
        # Fail closed - don't set CORS headers on error
    
    return {
        "statusCode": status_code,
        "headers": headers,
        "body": json.dumps(error_data, separators=(',', ':'))
    }